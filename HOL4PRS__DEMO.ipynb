{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE âš ** In order to run the code, go to `Runtime` >> and select the `Run all` options.\n"
      ],
      "metadata": {
        "id": "hwu2wmUrhatk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries and Files Installation**\n",
        "1. **Installation**: We start by installing the required packages, particularly `pytorch-lightning` version 1.8.3.\n",
        "\n",
        "2. **Imports**: We import necessary modules and libraries, including: `AutoTokenizer`, `AutoModel`, `transformers`, `numpy`, `pandas`, `LabelEncoder`, etc ...\n",
        "\n",
        "3. **Google Drive Authentication**: It authenticates with Google Drive to access specific files using the PyDrive library. This is done through the `auth.authenticate_user()` and related code.\n",
        "\n",
        "4. **File Retrieval**: We retreive necessary files from Google Drive using their unique IDs. These files include:\n",
        "   - A model checkpoint file (`best-checkpoint-v1.ckpt`).\n",
        "   - A label encoding file (`labelencoder.json`).\n",
        "   - Testing samples file `samples_id`."
      ],
      "metadata": {
        "id": "xkUzTGg28OkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==1.8.3 --quiet"
      ],
      "metadata": {
        "id": "vwRs5FZZuwXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import json\n",
        "import torch.nn as nn\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from typing import Optional\n",
        "import json"
      ],
      "metadata": {
        "id": "sH2s-Arp_hRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhRa1NsXypnb",
        "outputId": "bd19b591-732c-4d73-eb24-b2d8e87f9d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "checkpoint_id = '1eeWe9TqZ-vaPXZMf7gxHYnsuDDnlVcHI'\n",
        "encoding_id = '1sIoBeqALitCAbQOL24biTuXcaci7DjBy'\n",
        "samples_id = '1QfMlJd_DNTJVE4bMOIw_K1kAnJB2IY6z'\n",
        "\n",
        "checkpoint = drive.CreateFile({'id': checkpoint_id})\n",
        "checkpoint.GetContentFile('best-checkpoint-v1.ckpt')\n",
        "\n",
        "encoding = drive.CreateFile({'id': encoding_id})\n",
        "encoding.GetContentFile('labelencoder.json')\n",
        "\n",
        "samples = drive.CreateFile({'id': samples_id})\n",
        "samples.GetContentFile('samples_for_testing.txt')"
      ],
      "metadata": {
        "id": "fzg4-HGYypqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LuDnf4iLhZ-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Definitions**\n",
        "Here, we define classes and functions needing to generate the recommendations."
      ],
      "metadata": {
        "id": "E_RF9Z1i_i38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertTextClassifier(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        bert_model: str,\n",
        "        n_classes: int,\n",
        "        lr: float = 2e-5,\n",
        "        label_column: str = \"label\",\n",
        "        n_training_steps=None,\n",
        "        outputdir: str = \"outputs\",\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.bert_model = bert_model\n",
        "        self.label_column = label_column\n",
        "        self.bert = AutoModel.from_pretrained(bert_model, return_dict=True)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "        self.n_training_steps = n_training_steps\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.lr = lr\n",
        "        self.average_training_loss = None\n",
        "        self.average_validation_loss = None\n",
        "        self.outputdir = outputdir\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        output = self.classifier(output.pooler_output)\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.criterion(output, labels.long())\n",
        "        return loss, output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self(input_ids, attention_mask, labels)\n",
        "        outputs = torch.argmax(outputs, dim=1)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, logger=True, batch_size=len(batch))\n",
        "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self(input_ids, attention_mask, labels)\n",
        "        outputs = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, logger=True, batch_size=len(batch))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self(input_ids, attention_mask, labels)\n",
        "        outputs = torch.argmax(outputs, dim=1)\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, logger=True, batch_size=len(batch))\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "      return [optimizer]\n",
        "\n",
        "class BERTmodel:\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        print(\"BERTmode created\")\n",
        "\n",
        "    def from_pretrained(self, model_name=\"roberta-base\", tokenizer=None) -> None:\n",
        "        if tokenizer is not None:\n",
        "            self.tokenizer = tokenizer\n",
        "        else:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(f\"{model_name}\")\n",
        "            self.model = AutoModel.from_pretrained(\n",
        "                f\"{model_name}\", return_dict=True\n",
        "            )\n",
        "\n",
        "    def predict(text, model, tokenizer, max_length=120, top_k=7):\n",
        "\n",
        "        encoding = tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = model.to(device)\n",
        "        encoding[\"input_ids\"], encoding[\"attention_mask\"] = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "        _, test_prediction = model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
        "        top_k_values, top_k_indices = torch.topk(test_prediction, k=top_k, dim=-1)\n",
        "        with open(\"labelencoder.json\", 'r') as file:\n",
        "            data = json.load(file)\n",
        "        result = {}\n",
        "        preds = top_k_indices.tolist()[0]\n",
        "        for key, value in data.items():\n",
        "            if value in preds:\n",
        "                result[value] = key\n",
        "\n",
        "        preds = list(result.values())\n",
        "\n",
        "        return preds"
      ],
      "metadata": {
        "id": "b0Ge2Vrrt1Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, model, tokenizer, max_length=512, top_k=7):\n",
        "  encoding = tokenizer.encode_plus(\n",
        "    text,\n",
        "    max_length=max_length,\n",
        "    return_token_type_ids=False,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        "  )\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "  encoding[\"input_ids\"], encoding[\"attention_mask\"] = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "  _, test_prediction = model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
        "  top_k_values, top_k_indices = torch.topk(test_prediction, k=top_k, dim=-1)\n",
        "  with open(\"labelencoder.json\", 'r') as file:\n",
        "      data = json.load(file)\n",
        "  result = {}\n",
        "  preds = top_k_indices.tolist()[0]\n",
        "  for key, value in data.items():\n",
        "      if value in preds:\n",
        "          result[value] = key\n",
        "\n",
        "  preds = list(result.values())\n",
        "\n",
        "  return preds"
      ],
      "metadata": {
        "id": "lj0H4bAnt2QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tac_hist():\n",
        "    while True:\n",
        "        input_string = input(\"Please enter proof state: \")\n",
        "        input_string = input_string.upper().replace(\"_\", \"\")\n",
        "\n",
        "        if len(input_string.split()) < 3:\n",
        "            print(\"Current minimum tactics history is 3.\")\n",
        "            continue  # Ask again for input\n",
        "        else:\n",
        "            break\n",
        "    return input_string"
      ],
      "metadata": {
        "id": "NtHXAYfwzSLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recom(proof_state, roberta_model, tokenizer):\n",
        "  recom = predict(proof_state, roberta_model, tokenizer)\n",
        "  recomendations = []\n",
        "  for string in recom:\n",
        "    modified_tac = string.replace(\"TAC\", \"_TAC\")\n",
        "    modified_tac = modified_tac.replace(\"REPEAT\", \"REPEAT \")\n",
        "    recomendations.append(modified_tac)\n",
        "  print(\"HOL4PRS reccommendations are: \", recomendations)"
      ],
      "metadata": {
        "id": "Kc2fKaWXzSZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Try HOL4PRS**\n",
        "\n"
      ],
      "metadata": {
        "id": "7-JXF75y5D0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Loading the tokenizer and the trained model file**"
      ],
      "metadata": {
        "id": "lFSIn8XPfK_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = BertTextClassifier.load_from_checkpoint(checkpoint_path=\"best-checkpoint-v1.ckpt\", bert_model=\"roberta-base\", n_classes=162)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vY93qJdt2V0",
        "outputId": "4ed54487-4dd6-4a3e-87ef-8b3afdee940e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Demo**\n",
        "In the files section on the left ðŸ“‚, you've uploaded a text file containing proof samples. To test the tool, you can input a part of the proof and observe the tool's recommendation for the next step.\n"
      ],
      "metadata": {
        "id": "Hc1sz3BuemXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter proof state\n",
        "proof_state = read_tac_hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iAphRZQzSWT",
        "outputId": "dc4751a3-f2ac-4b52-f55d-ef4584aa84b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter proof state: ONCE_REWRITE_TAC MATCH_MP_TAC BETA_TAC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate recommendation\n",
        "get_recom(proof_state, roberta_model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrioPO3-3Vg8",
        "outputId": "d106308e-a5d9-427b-b393-ee1a8111d463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOL4PRS reccommendations are:  ['ASMSIMP_TAC', 'MESON_TAC', 'METIS_TAC', 'REPEAT STRIP_TAC', 'REWRITE_TAC', 'SET_TAC', 'SIMP_TAC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xmvr2t91gN2j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
